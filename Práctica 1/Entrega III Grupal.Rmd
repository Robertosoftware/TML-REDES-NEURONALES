---
title: "Entrega II Grupal"
description: |
  Entrega Housing Regression
author:
  - name: Irving Ram铆rez Carrillo, Asier Zulaica Mugica, Roberto Bonilla Ibarra
    url: 
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 8, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Objetivo {#objetivo}

El objetivo de esta entrega es poder predecir el precio de vivienda usando al menos un modelo de regresi贸n univariante (eligiendo la que mejor se considere), un modelo saturado, una regresi贸n con selecci贸n de modelos (BIC / AIC o penalizada) y un knn o 谩rbol en modo regresi贸n.

## Paquetes necesarios

Necesitaremos los siguientes paquetes


```{r paquetes}
# Borramos
rm(list = ls())

# Paquetes
library(skimr) # resumen num茅rico
library(tidymodels) # depuraci贸n datos
library(tidyverse) # modelos
library(outliers) # outliers
library(timeDate) # fechas
library(ggthemes) # tema para graficar
library(ranger) # Random Forest 
library(corrr) # Crear correlaciones
library(Hmisc) # Creaci贸n de histogramas
library(performance) # Creaci贸n de gr谩ficas de performance para regresiones lineales.
library(corrplot) # Crear matriz de correlaci贸n
library(parallel) # Librer铆as de C贸mputo en Paralelo
library(doParallel) # Librer铆as de C贸mputo en Paralelo
library("rpart.plot") # Librer铆a para visualizar la l贸gica dentro del algoritmo de 谩rboles.
library(vip) # Librer铆a para visualizar la importancia de las variables dentro del algoritmo de 谩rboles.
library(olsrr) #Librer铆a para realizar contraster de normalidad
library(car)  # Comprobar la incorrelaci贸n de residuos
```

# Datos {#datos}

Haremos uso de un **dataset de precios de viviendas con distintas variables socioecon贸micas.**

```{r}
viviendas_train <- read_csv(file = "../Data/house_prices_train.csv")
```

Los datos forman parte de un **registro de diferentes variables relacionadas al precio de vivienda en Ames ,Iowa** elaborado por Dean De Cock.

 **Detalle de variables**: <https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview>


## An谩lisis exploratorio inicial (num茅rico)

Antes de tomar ninguna decisi贸n con los datos lo primero que deber铆amos hacer es **echar un vistazo num茅rico** a c贸mo se comportan las variables. Dado que vamos a clasificar, lo primero que deber铆amos observar es como se distribuyen los niveles de nuestra variable objetivo.

### Variables

Lo primero es conocer las variables

```{r}
glimpse(viviendas_train)
```

Siendo la definici贸n de cada variable la siguiente:

*	SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.
*	MSSubClass: The building class
*	MSZoning: The general zoning classification
*	LotFrontage: Linear feet of street connected to property
*	LotArea: Lot size in square feet
*	Street: Type of road access
*	Alley: Type of alley access
*	LotShape: General shape of property
*	LandContour: Flatness of the property
*	Utilities: Type of utilities available
*	LotConfig: Lot configuration
*	LandSlope: Slope of property
*	Neighborhood: Physical locations within Ames city limits
*	Condition1: Proximity to main road or railroad
*	Condition2: Proximity to main road or railroad (if a second is present)
*	BldgType: Type of dwelling
*	HouseStyle: Style of dwelling
*	OverallQual: Overall material and finish quality
*	OverallCond: Overall condition rating
*	YearBuilt: Original construction date
*	YearRemodAdd: Remodel date
*	RoofStyle: Type of roof
*	RoofMatl: Roof material
*	Exterior1st: Exterior covering on house
*	Exterior2nd: Exterior covering on house (if more than one material)
*	MasVnrType: Masonry veneer type
*	MasVnrArea: Masonry veneer area in square feet
*	ExterQual: Exterior material quality
*	ExterCond: Present condition of the material on the exterior
*	Foundation: Type of foundation
*	BsmtQual: Height of the basement
*	BsmtCond: General condition of the basement
*	BsmtExposure: Walkout or garden level basement walls
*	BsmtFinType1: Quality of basement finished area
*	BsmtFinSF1: Type 1 finished square feet
*	BsmtFinType2: Quality of second finished area (if present)
*	BsmtFinSF2: Type 2 finished square feet
*	BsmtUnfSF: Unfinished square feet of basement area
*	TotalBsmtSF: Total square feet of basement area
*	Heating: Type of heating
*	HeatingQC: Heating quality and condition
*	CentralAir: Central air conditioning
*	Electrical: Electrical system
*	1stFlrSF: First Floor square feet
*	2ndFlrSF: Second floor square feet
*	LowQualFinSF: Low quality finished square feet (all floors)
*	GrLivArea: Above grade (ground) living area square feet
*	BsmtFullBath: Basement full bathrooms
*	BsmtHalfBath: Basement half bathrooms
*	FullBath: Full bathrooms above grade
*	HalfBath: Half baths above grade
*	Bedroom: Number of bedrooms above basement level
*	Kitchen: Number of kitchens
*	KitchenQual: Kitchen quality
*	TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)
*	Functional: Home functionality rating
*	Fireplaces: Number of fireplaces
*	FireplaceQu: Fireplace quality
*	GarageType: Garage location
*	GarageYrBlt: Year garage was built
*	GarageFinish: Interior finish of the garage
*	GarageCars: Size of garage in car capacity
*	GarageArea: Size of garage in square feet
*	GarageQual: Garage quality
*	GarageCond: Garage condition
*	PavedDrive: Paved driveway
*	WoodDeckSF: Wood deck area in square feet
*	OpenPorchSF: Open porch area in square feet
*	EnclosedPorch: Enclosed porch area in square feet
*	3SsnPorch: Three season porch area in square feet
*	ScreenPorch: Screen porch area in square feet
*	PoolArea: Pool area in square feet
*	PoolQC: Pool quality
*	Fence: Fence quality
*	MiscFeature: Miscellaneous feature not covered in other categories
*	MiscVal: $Value of miscellaneous feature
*	MoSold: Month Sold
*	YrSold: Year Sold
*	SaleType: Type of sale
*	SaleCondition: Condition of sale

`Fuente: ` <https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data>

Adem谩s con la funci贸n `skim()` del paquete `{skimr}` podemos **extraer algunas estad铆sticas b谩sicas** de nuestros datos.

```{r skim}
# Resumen num茅rico
viviendas_train |> skim()
```



Podemos ver que nuestro dataset de entrenamiento cuenta con 1460 columnas, 28 columnas categ贸ricas y 24 num茅ricas, adem谩s podemos apreciar que existen variables como `PoolQc` o `Fence` que son en su mayor铆a nulas.


# Limpieza de datos e imputaci贸n de nulos.

En est谩 ocasi贸n antes de proceder a realziar un an谩lisis exploratorio exhaustivo y por la necesidad de entender la correlai贸n entre nuestras variables, procederemos a limpiar de nulos nuestros datos.


**Primero:** Uniremos los datos a帽adiendo una columna que especifique si los datos son de entrenamiento 贸 de testing.

```{r}
viviendas_test <- read_csv(file = "../Data/house_prices_test.csv")

viviendas_test <- viviendas_test |> mutate(source = "test")

viviendas_train <- viviendas_train |> mutate(source = "train")

viviendas <-  viviendas_train |> bind_rows(viviendas_test)

glimpse(viviendas)
```

**Segundo:** Analicemos los nulos de nuestro dataset completo

```{r}
# N煤mero de valores nulos
viviendas_nulos <- viviendas %>%  select(-SalePrice)

null_vals <- sum(is.na(viviendas_nulos))

# C贸lumnas con valores nulos
null_cols <- which(colSums(is.na(viviendas_nulos))>0)


sprintf(fmt="Contamos con %d valores nulos y su distribuci贸n es la siguiente:\n", null_vals) |>  cat()

for (i in null_cols)
    {
    col_name <- names(viviendas_nulos[, i])
    col_type <- sapply(viviendas_nulos[, i],class)
    null_val <- sum(is.na(viviendas_nulos[col_name]))
    null_per <- (null_val / nrow(viviendas_nulos))*100
    sprintf(fmt = "- %s: %d (%.1f%%)  %s\n ", 
            col_name, null_val, null_per,col_type) %>% cat()
}

```

Podemos ver que tenemos nulos en 5 variable num茅ricas y 13 categ贸ricas.

## Limpieza variables categ贸ricas


### Limpieza variables Alley, FireplaceQu, GarageQual, PoolQC, BsmtQual, BsmtCond y Fence

Por la distribuci贸n de cada una de estas variables las analizaremos y limpiaremos en la misma secci贸n

```{r}
# Revisando variable Alley
viviendas |>   count(Alley, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable FireplaceQu
viviendas |>   count(FireplaceQu, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable GarageQual
viviendas |>   count(GarageQual, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable PoolQC
viviendas |>   count(PoolQC, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable BsmtQual
viviendas |>   count(BsmtQual, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable BsmtCond
viviendas |>   count(BsmtCond, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable Fence
viviendas |>   count(Fence, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

```

Podemos ver que no hace sentido quedarnos con la variable `PoolQC` ya que tiene muchos valores nulos (99%) y contamos con `PoolArea` y por lo tanto pasaremos a eliminarla:


```{r}
viviendas <- viviendas %>% select(-PoolQC)
```

Podemos ver que estas variables realmente es que no cuentan con las instalaciones que se est谩n evaluando, por lo tanto, en cada uno de ellos a帽adiremos la categoria "sin":


```{r}

viviendas <- viviendas %>% 
    mutate_at(c('Fence','GarageQual','FireplaceQu','Alley','BsmtQual','BsmtCond'), ~replace_na(.,"sin"))

```



### Limpieza variable MSZoning

Analicemos la distribuci贸n de la variable MSZoning

```{r}

viviendas |>   count(MSZoning, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

```


De acuerdo a la documentaci贸n, el significado de cada clase es el siguiente:

* A	Agriculture
* C	Commercial
* FV	Floating Village Residential
* I	Industrial
* RH	Residential High Density
* RL	Residential Low Density
* RP	Residential Low Density Park 
* RM	Residential Medium Density
       
Por lo tanto asignaremos los registros en nulo a la categor铆a con mayor porcentaje.


```{r}

viviendas$MSZoning <- viviendas$MSZoning |> replace_na('RL')

```

### Limpieza variables Utilities, Exterior1st, Electrical, KitchenQual, Functional, SaleType

Porque los nulos se encuentran con baja densidad en estas variables, las analizaremos y limpiaremos en conjunto:

```{r}
# Revisando variable  Utilities
viviendas |>   count(Utilities, sort = TRUE) |>
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable Exterior1st
viviendas |>   count(Exterior1st, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable Electrical
viviendas |>   count(Electrical, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable KitchenQual
viviendas |>   count(KitchenQual, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable Functional
viviendas |>   count(Functional, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

# Revisando variable SaleType
viviendas |>   count(SaleType, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))

```

Podemos ver que la columna `Utilities` es pr谩cticamente de varianza cero y procederemos a removerla.

```{r}
 viviendas <- viviendas |> select(-Utilities)
```


Para las dem谩s variables hace sentido asignar la moda ya que son muy pocos registros y no hace sentido crear una nueva categor铆a.


```{r}
# Funci贸n de calcular moda
calc_mode <- function(x){
  
  # Enlistar los distintos valores
  distinct_values <- unique(x)
  
  # Calcular la frecuencia de cada valor 煤nico
  distinct_tabulate <- tabulate(match(x, distinct_values))
  
  # Seleccionar la moda
  distinct_values[which.max(distinct_tabulate)]
}

# Transformando las columnas categ贸ricas restantes
viviendas <- viviendas |> mutate(across(where(is.character),~replace_na(.x, calc_mode(.x))))
```


## Limpieza variables num茅ricas

Analicemos el resumen de las variables num茅ricas que tienen un valor nulo:

```{r}
# Selecci贸n de variables num茅ricas con nulos
null_numeric_cols <- names(which(colSums(is.na(viviendas_nulos |>  select(where(is.numeric))))>0))

# Resumen de variables num茅ricas con nulos
viviendas |> select(null_numeric_cols) |> summary()
```


### Variable GarageCars,GarageArea, TotalBsmtSF

Podemos ver que estas 3 variables realmente es porque el due帽o de cada casa no cuenta con la variable, es decir, deber铆an de ser 0.

```{r}

viviendas <- viviendas |> 
    mutate(across(c(GarageCars,GarageArea, TotalBsmtSF), ~replace_na(.x,0) ))
```



### Variable Lot Frontage

Podemos ver que en la variable Lot Frontage tenemos outliers presentes en los datos, sin embargo, analizemos m谩s de fondo.

#### Coeficiente de variaci贸n

El coeficiente de variaci贸n es la relaci贸n entre la desviaci贸n t铆pica de una muestra y su media.

${CV} = \frac{{\sigma}{\mu}} 

```{r}
sd(viviendas$LotFrontage,na.rm=TRUE) / mean(viviendas$LotFrontage,na.rm=TRUE)
```
Esto nos dice que existe una dispersi贸n considerable en nuestros datos y ser谩 mejor medida imputar por la mediana, sin embargo, podemos darle un valor por el tipo de construcci贸n o por el n煤mero de autos.


```{r}
ggplot(viviendas, aes(x = factor(BldgType), y = LotFrontage, color=factor(BldgType))) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Imputaci贸n de nulos",
       subtitle = "Distribuci贸n del Lot Frontage por tipo de hogar",
       x = "Tipo de hogar", y = "Lot Frontage", color= "Tipo de hogar") +
  theme_economist()
```

Vemos que el tipo de construcci贸n no tiene relevancia con la variable Lot Frontage.


```{r}
ggplot(viviendas, aes(x = factor(GarageCars), y = LotFrontage, color=factor(GarageCars))) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Imputaci贸n de nulos",
       subtitle = "Distribuci贸n del Lot Frontage por n煤mero de autos",
       x = "N煤mero de autos", y = "Lot Frontage", color= "n煤mero de autos") +
  theme_economist()
```

Vemos que el n煤mero de autos marca una tendencia con la variable Lot Frontage, por lo tanto pasaremos a imputar con la mediana de cada grupo



```{r}
# Decidimos asignar la mediana a los valores nulos de Lo

viviendas <- viviendas |> group_by(GarageCars) %>% 
    mutate(across(c(LotFrontage),function(x) { ifelse(is.na(x), median(x, na.rm = TRUE), x) })) %>%  ungroup()

```

### Variable GarageYrBlt

Podemos ver que esta variable adem谩s de tener nulos, tenemos errores en los datos como el a帽o `2207`.

Primero imputaremos la variable GarageYrBlt por el a帽o de construcci贸n de la vivienda

```{r}
viviendas <- viviendas |> 
   mutate(GarageYrBlt  = coalesce(GarageYrBlt,YearBuilt))
```

Despu茅s veamos en un histograma su distribuci贸n:

```{r}
ggplot(viviendas, aes(x = GarageYrBlt)) + 
    geom_histogram(bins = 50, color="blue", fill="gold") +
    labs(title = "Variable GarageYrBlt",
          x = "GarageYrBlt", 
         y = "Frecuencia") +
  theme_economist()
```

Vemos que solo existe un dato que no hace sentido, el cu谩l es:

```{r} 
viviendas %>% slice_max(GarageYrBlt,n=10) %>%  select(GarageYrBlt, YearBuilt)

```
Una casa que se contruy贸 en el 2006, por lo tanto le remplazaremos el valor con el a帽o en que se contruyo el lugar


```{r} 
viviendas <- viviendas %>% 
  mutate(GarageYrBlt = ifelse(GarageYrBlt==2207,YearBuilt, GarageYrBlt))
```


Veamos como se ven las variables imputadas:
```{r}
viviendas |> select(null_numeric_cols) |> summary()
```


# Fase 1: Muestreo

Como nuestros datos de entrenamiento son reducidos, no necesitamos hacer alguna muestra de ellos.

# Fase 2: Exploratorio

Antes de poder tomar decisiones en c贸mo transformar nuestros datos es importante poder hacer un an谩lisis detallado visual de nuestros datos y conocer c贸mo interact煤an con la variable objetivo.

Para esto usaremos el tema del economist.

## Distribuci贸n visual variable objetivo

Veamos c贸mo se distribuye nuesta variable objetivo

```{r}
ggplot(viviendas, aes(x = SalePrice)) + 
    geom_histogram(bins = 50) +
    labs(title = "Variable Objetivo",
         subtitle = "Precio de venta",
          x = "Cantidad en d贸lares ($)", 
         y = "Frecuencia") +
  theme_economist()

```

Podemos ver que es unimodal, con sesgo positivo y ciertos outliers que se pueden dislumbrar r谩pidamente.

## An谩lisis de variables num茅ricas


```{r}
hist.data.frame(viviendas |>   select(where(is.numeric)))
```

Podemos ver que tenemos variables num茅ricas con Outliers como la variable PoolArea, OpenPorchSF, LotFrontage, LotArea, TotalBsmtSF, 1stFlrSF, 2ndFlrSF y SalePrice.

Adem谩s existen variables num茅ricas que realmente representan una categor铆a como Fireplaces, GarageCars, FirePlaces, OverallCond, MoSold, BedroomAbvGr, entre otras.

## An谩lisis de variables categ贸ricas



```{r}

hist.data.frame(viviendas |>   select(where(is.character)))

```

Podemos ver que existen variables que necesitaremos revisar su distribuci贸n ya que son pr谩cticamente constantes como la variable Central Air, Street, LandContour y LandSlope, adem谩s de que algunas variables son ordinales como ExterCond, BmstQual, BsmtCond, KitchenQual, HeatinQC, FireplaceQu y GarageQual. 

## Limpieza Outliers

### Correci贸n variables num茅ricas

Analicemos los estad铆sticos de las variables: PoolArea, OpenPorchSF, LotFrontage, LotArea, TotalBsmtSF, 1stFlrSF y 2ndFlrSF.

```{r}
viviendas |>  select(PoolArea,OpenPorchSF,LotFrontage,LotArea,TotalBsmtSF,'1stFlrSF','2ndFlrSF') %>% summary()
```

Ahora veamos sus coeficientes de variaci贸n:


```{r}

cv <- function(x) 100*( sd(x)/mean(x))

   viviendas %>%
   select(PoolArea,OpenPorchSF,LotFrontage,LotArea,TotalBsmtSF,'1stFlrSF','2ndFlrSF')%>%
     summarise_each(funs( cv))
```

Podemos ver que la variable Pool Area no hace sentido en su distribuci贸n actual por su dispersi贸n tan elevada, como es el caso tambi茅n de OpenPorch, LotArea y 2ndFlrsF.


```{r}
ggplot(viviendas, aes(x = PoolArea)) + 
    geom_histogram(bins = 25, color="blue", fill="gold") +
    labs(title = "Variable PoolArea",
          x = "PoolArea", 
         y = "Frecuencia") +
  theme_economist()
```
Y asignando una ra铆z cuadrada a los valores

```{r}
ggplot(viviendas, aes(x = sqrt(PoolArea))) + 
    geom_histogram(bins = 25, color="blue", fill="gold") +
    labs(title = "Variable PoolArea",
          x = "PoolArea", 
         y = "Frecuencia") +
  theme_economist()

```

Vemos que los valores se han alejado menos entre ellos, pero siguen sumamente alejando, por lo tanto les asignaremos dividiremos en 5 niveles los valores (por sus quantiles), dejando los valores con 0 por fuera y con el mismo valor.

```{r}
quantile_pool <- viviendas %>%
    filter(PoolArea > 0) %>%
    mutate(Poolquantile = cut(PoolArea, breaks = 5, labels = c(1:5))) %>% 
    select(Id,Poolquantile)


viviendas <- viviendas %>%
    full_join(quantile_pool, by = "Id") %>%
    mutate(Poolquantile = ifelse (is.na(Poolquantile), 0, Poolquantile))

```


```{r}
hist.data.frame(viviendas |>   select(Poolquantile))
```

Las variables restantes, al no tener el mismo grado de dispersi贸n, les aplicaremos boxcox directamente en la receta y filtraremos sus at铆picos por medio de su z score.

### Correci贸n variables categ贸ricas

#### Street

Veamos la distribuci贸n de la variable Street

```{r}
ggplot(viviendas, aes(x = Street)) + 
    geom_histogram(stat = "count", color="blue", fill="gold") +
  stat_count(binwidth = 1, 
             geom = 'text', 
             color = 'black', 
             aes(label = ..count..),
           position = position_stack(vjust = 0.5)) +
    labs(title = "Variable Street",
          x = "Street", 
         y = "Frecuencia") +
  theme_economist()
```

Podemos ver que es menos del 1% por lo tanto procederemos a eliminar esta variable


```{r}
viviendas <- viviendas |> select(-Street) 

```


#### Id

Como podemos saber esta variable no importa ninguna informaci贸n acerca del precio de la casa, por lo tanto, la eliminaremos:


```{r}
viviendas <- viviendas |> select(-Id) 

```


## Correlaci贸n entre variables

En vez de graficar todas las relaciones entre nuestras variables, entenderemos su correlaci贸n entre ellas y la variable objetivo, para as铆 poder determinar qu茅 an谩lisis exploratorio hace sentido.


Primero separaremos nuestro dataset train

```{r}
viviendas_cleaned_train <- viviendas |> filter(source=="train") 

```

Despu茅s realizaremos la matriz de correlaci贸n
```{r}
cor_matrix <- viviendas_cleaned_train |> select(where(is.numeric)) |> cor() |> round(2)

cor_matrix |>
  corrplot( order = 'AOE', type = 'upper') 
```


Y veamos la variables m谩s correlacionadas:


```{r}
cor_matrix_rm <- viviendas_cleaned_train |> select(where(is.numeric)) |>select(-SalePrice) |>  cor() |> round(2)

cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
diag(cor_matrix_rm) <- 0
which((!apply(cor_matrix_rm, 1,function(x) any(x > 0.7)))==FALSE)

```
Podemos ver que hay 4 variables que se encuentran incorreladas

Ahora extraigamos por orden descendiente las correlaciones entre nuestras variables y `SalePrice`:

```{r}

as.data.frame(cor_matrix)  |> select(SalePrice) |> arrange(desc(SalePrice))

```

Podemos ver con claridad que las variables que quitaremos en la receta es 1stFlrSF, TotRmsAbvGrd y GarageYrBlt, ya que existen variables similares a ellas con mayor correlaci贸n con la variable objetivo.

Con base a los resultados anteriores nos podemos preguntar lo siguiente:

* **1. 驴Qu茅 relaci贸n tiene el n煤mero de veh铆culos con el costo de la propiedad?**
* **2. 驴Las casas con 谩reas verdes m谩s grandes tienden a ser m谩s costosas?**
* **3. 驴Existe una relaci贸n directa entre el precio y la Zona?**
* **4. 驴Las casas con mejores cocinas tienden a ser m谩s costosas?**

### 驴Qu茅 relaci贸n tiene el n煤mero de veh铆culos con el costo de la propiedad?

Antes de graficar podemos observar que GarageCars es un factor y por lo tanto es necesario especificarlo en ggplot.

```{r}
ggplot(viviendas_cleaned_train, aes(x = factor(GarageCars), y = SalePrice, color=factor(GarageCars))) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Pregunta 1",
       subtitle = "Distribuci贸n del precio de venta por n煤mero de veh铆culos en el garage",
       x = "# Veh铆culos", y = "Precio de Venta", color= "Veh铆culos") +
  theme_economist()
```

Podemos ver que existe una relaci贸n del n煤mero de veh铆culos con el precio de venta, sin embargo, est谩 no se respeta cuando se llega al n煤mero de 4 autos.

### 驴Las casas con 谩reas verdes m谩s grandes tienden a ser m谩s costosas?


```{r}
ggplot(viviendas_cleaned_train, aes(x =GrLivArea , y = SalePrice)) +
  geom_point(aes( size=GarageArea, color=HeatingQC)) +
    geom_smooth(method = "lm", se = FALSE, color="gold") +
  scale_color_brewer(palette="Accent")+
   labs(title = "Pregunta 2",
       subtitle = "Distribuci贸n del precio de venta vs tama帽o del 谩rea verde",
       x = "rea verde", y = "Precio de Venta") +
  theme_economist()
```


Podemos ver que s铆 existe una relaci贸n directa entre el precio de venta y el 谩rea verde de la casa, adem谩s vemos que la calidad de la calefacci贸n tambi茅n es una cualidad de las casas m谩s costosas y el amplio tama帽o del Garage.


### 驴Existe una relaci贸n directa entre el precio y el vecindario?


```{r}
ggplot(viviendas_cleaned_train, aes(x = MSZoning, y = SalePrice, color=MSZoning)) +
  geom_violin() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Pregunta 3",
       subtitle = "Distribuci贸n del Precio de Venta y Zona",
       x = "Zona", y = "Precio de Venta", color= "Zona") +
  theme_economist()
```

Podemos ver que s铆 existe una diferenciaci贸n de precios por 

### 驴Las casas con mejores cocinas tienden a ser m谩s costosas?


```{r}
ggplot(viviendas_cleaned_train, aes(x = KitchenQual, y = SalePrice, color=KitchenQual)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Pregunta 4",
       subtitle = "Distribuci贸n del Precio de Venta y el Tipo de Cocina",
       x = "Tipo de Cocina", y = "Tipo de Cocina", color= "Tipo de Cocina") +
  theme_economist()

```
Podemos ver que s铆 hay una relaci贸n entre el tipo de cocina y el costo de la vivienda.

# Fase 3: Modificaci贸n (fuera de la receta)

## Factores

Una de las primeras decisiones ser谩 dotar a las variables de su **tipolog铆a correcta**: debemos decidir si las variables de tipo texto son **variables cualitativas** (factores) o simplemente id's.

```{r}
viviendas |>
  select(where(is.character)) |>
  glimpse()
```


Todas las variables de tipo texto representan **categor铆as de una cualitativa** as铆 que las convertimos todas ellas a factor (modificaci贸n estructural --> fuera de la receta)

```{r}

viviendas <- 
  viviendas |>
  mutate(across(where(is.character), as_factor))

```

Y adem谩s crearemos una nueva variable que representa el n煤mero de ba帽os totales:
```{r}
viviendas <-
  viviendas |>
  mutate( Baths = (FullBath*2  + HalfBath))
```


Y a帽adiremos como factor las variables Baths, Fireplaces, GarageCars, Fireplaces, OverallCond, MoSold y BedroomAbvGr.

```{r}
viviendas <- 
  viviendas |>
  mutate(across(c(Baths,Fireplaces,GarageCars,Fireplaces,OverallCond,MoSold,BedroomAbvGr), as_factor))
```

Ahora veamos todos los factores que est谩n en la tabla.

```{r}
viviendas |> select(where(is.factor))
```

### Ordinales

Podemos ver que de nuestros factores, existen algunos con caracter铆sticas ordinales.

Transformaremos los factores  GarageQual, FireplaceQu, KitchenQual, HeatingQC, BsmtCond, BsmtQual y ExterCond

Primero veamos su distribuci贸n:

```{r}
# Variable GarageQual
viviendas |>
  count(GarageQual) |> 
  mutate(porc = 100*n/sum(n))

# Variable FireplaceQu
viviendas |>
  count(FireplaceQu) |> 
  mutate(porc = 100*n/sum(n))

# Variable KitchenQual
viviendas |>
  count(KitchenQual) |> 
  mutate(porc = 100*n/sum(n))

# Variable HeatingQC
viviendas |>
  count(HeatingQC) |> 
  mutate(porc = 100*n/sum(n))

# Variable BsmtCond
viviendas |>
  count(BsmtCond) |> 
  mutate(porc = 100*n/sum(n))

# Variable BsmtQual
viviendas |>
  count(BsmtQual) |> 
  mutate(porc = 100*n/sum(n))

# Variable ExterCond
viviendas |>
  count(ExterCond) |> 
  mutate(porc = 100*n/sum(n))
```


Ahora les asignaremos un orden a cada categor铆a con base a lo que nos espec铆fica la documentaci贸n:

* `Ex	Excellent`
* `Gd	Good`
* `TA	Average/Typical`
* `Fa	Fair`
* `Po	Poor`

```{r}

viviendas <-
  viviendas |>
  mutate(GarageQual = factor(GarageQual, levels = c("sin","Po", "Fa","TA", "Gd", "Ex"),ordered = TRUE),
         FireplaceQu = factor(FireplaceQu, levels = c("sin","Po", "Fa","TA", "Gd", "Ex"),ordered = TRUE),
         KitchenQual = factor(KitchenQual, levels = c("Fa","TA", "Gd", "Ex"),ordered = TRUE),
         HeatingQC = factor(HeatingQC, levels = c("Po", "Fa","TA", "Gd", "Ex"),ordered = TRUE),
         BsmtCond = factor(BsmtCond, levels = c("sin","Po", "Fa","TA", "Gd"),ordered = TRUE),
         BsmtQual = factor(BsmtCond, levels = c("sin", "Fa","TA", "Gd", "Ex"),ordered = TRUE),
         ExterCond = factor(ExterCond, levels = c("Fa","Po","TA", "Gd", "Ex"),ordered = TRUE)
         )
knitr::kable(viviendas |> select(GarageQual, FireplaceQu, KitchenQual, HeatingQC, BsmtCond, BsmtQual, ExterCond) |> slice_sample(n=10) )
```

## Separaci贸n Original

Por 煤ltimo separaremos nuestro dataset en Train y Test como originalmente se encontraba.


```{r}

viviendas_train <- viviendas |> filter(source=="train") |> select(-source)


viviendas_test <- viviendas |> filter(source=="test") |> select(-source)

```

# Fase 3: Modificaci贸n (dentro de la receta)


### Partici贸n

#### Train - Test Partici贸n

Partiremos nuestros datos en train 85% y test 15%, esto lo usaremos para encontrar los mejores par谩metros.

```{r}
# Partici贸n 10% de test 
viviendas_split <- initial_split(viviendas_train, prop = 0.85)
viviendas_split
```

F铆jate que en `viviendas_split` solo tenemos las instrucciones. Vamos a aplicarlas

```{r}
# Aplicamos partici贸n
train_data <- training(viviendas_split)
test_data <- testing(viviendas_split)
```


#### Validaci贸n por Partici贸n 

Est谩 validaci贸n la usaremos para los modelos univariantes, modelos saturados y regresiones con selecci贸n de modelos.
```{r}
# Validaci贸n
validation_data <- validation_split(viviendas_train, prop = 0.7)
```


#### Validaci贸n Cruzada

Para los modelos que necesitaremos hiperparametrizar usaremos validaci贸n cruzada con repetici贸n.

```{r}
# Declaramos el n煤mero de particiones en las que procederemos a validar.
cv_folds <-
 vfold_cv(train_data, 
          v = 4, 
          repeats = 1) 
```


### Roles

Tras las particiones, el primer paso es **definir la receta**, indic谩ndole el conjunto donde tenemos validaci贸n y train. Despu茅s lo que haremos ser谩 **asignar posibles roles** que nos puedan diferencias las acciones entre las variables


```{r}
# Receta
rec_viviendas <-
  # F贸rmula y datos
  recipe(data = train_data, SalePrice ~ .)|>
  # Roles
  add_role(where(is.factor), new_role = "cuali") |> 
  add_role(where(is.numeric), new_role = "cuanti") |> 
  add_role(c(FullBath, HalfBath, '1stFlrSF', TotRmsAbvGrd,GarageYrBlt, PoolArea ), new_role = "Drop_Columns") %>% 
  add_role(c(OpenPorchSF,TotalBsmtSF,'2ndFlrSF',LotFrontage,LotArea ), new_role = "boxcox_var")
```


###Receta Regresi贸n Univariante

Ahora procederemos en crear la receta para la regresi贸n univariante.

```{r}
# Receta
rec_reg_viviendas <-
  # F贸rmula y datos
  recipe(data = train_data, SalePrice ~ GrLivArea) %>% 
  step_log(GrLivArea, base = 10) %>%
  # los dem谩s imputamos por la media
  step_mutate(GrLivArea = ifelse(abs(scores(GrLivArea, type = "z")) > 3, NA, GrLivArea)) %>% 
  step_impute_mean(GrLivArea)
rec_reg_viviendas
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data <- 
  rec_reg_viviendas |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data)
```

### Receta Modelo Saturado

Ahora procederemos en crear la receta para la regresi贸n saturada.

```{r}
# Receta
rec_reg_saturada <-
  # F贸rmula y datos
  rec_viviendas |> 
  step_rm(has_role("Drop_Columns")) |>
  step_BoxCox(has_role("boxcox_var")) |>
  step_mutate(across(all_numeric_predictors(), function(x) { ifelse(abs(scores(x,type = "z")) > 2.7 & !is.na(x), NA, x) })) |>
  step_impute_knn(all_numeric_predictors()) |> 
  step_impute_mode(has_role("cuali")) |>
  step_other(has_role("cuali"), threshold = .1, other = "Otros")  |> 
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(all_numeric_predictors(), threshold = 0.8)
rec_reg_saturada
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data <- 
  rec_reg_saturada |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data)
```


### Receta Regresi贸n con Selecci贸n de Modelos BIC

Ahora procederemos en crear la receta para la regresi贸n penalizada usando el modelo Elastic Net.

```{r}
# Receta
rec_reg_bic <-
  # F贸rmula y datos
  rec_viviendas |> 
  step_rm(has_role("Drop_Columns")) |> 
  step_BoxCox(has_role("boxcox_var")) |>
  step_sqrt(SalePrice) |> 
  step_mutate(across(all_numeric_predictors(), function(x) { ifelse(abs(scores(x,type = "z")) > 2.7 & !is.na(x), NA, x) })) |>
  step_impute_knn(all_numeric_predictors()) |> 
  step_impute_mode(has_role("cuali")) |>
  step_other(has_role("cuali"), threshold = .15, other = "Otros")  |> 
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(all_numeric_predictors(), threshold = 0.8)
rec_reg_bic
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data_bic <- 
  rec_reg_bic |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data_bic)
```



### Receta Regresi贸n Penalizada (Elastic Net)

Ahora procederemos en crear la receta para la regresi贸n penalizada usando el modelo Elastic Net.

```{r}
# Receta
rec_reg_elastic <-
  # F贸rmula y datos
  rec_viviendas |> 
  step_rm(has_role("Drop_Columns")) |> 
  step_BoxCox(has_role("boxcox_var")) |>
  step_sqrt(SalePrice) |> 
  step_mutate(across(all_numeric_predictors(), function(x) { ifelse(abs(scores(x,type = "z")) > 2.7 & !is.na(x), NA, x) })) |>
  step_impute_knn(all_numeric_predictors()) |> 
  step_impute_mode(has_role("cuali")) |>
  step_other(has_role("cuali"), threshold = .2, other = "Otros")  |> 
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(all_numeric_predictors(), threshold = 0.8)
rec_reg_elastic
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data <- 
  rec_reg_elastic |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data)
```



# Fase 4 Modelling

## Fase 4 Regresi贸n Univariante

### Flujo y Evaluaci贸n Regresi贸n Univariante


Primero generamos el modelo lineal, el flujo y evaluamos el modelo con los datos de validaci贸n.

```{r}
# Modelo lineal
reg_lineal <- linear_reg() %>% set_mode("regression") %>% set_engine("lm")

# Flujo de Trabajo
reg_wflow_viviendas <-
  workflow() %>% 
  add_model(reg_lineal) %>% 
  add_recipe(rec_reg_viviendas)

# Evaluaci贸n del modelo a los datos de validaci贸n
reg_fit_viviendas <- 
  reg_wflow_viviendas %>%
  fit_resamples(resamples = validation_data)

# M茅tricas de error
reg_fit_viviendas |> collect_metrics()


```
Podemos ver que el R cuadrada es de .45 y el RMSE es de 56,918 d贸lares, esto nos da a simple vista resultados de un modelo muy pobre en rendimiento.


### Interpretaci贸n de resultados

```{r}
reg_fit_viviendas <-  reg_wflow_viviendas %>% fit(viviendas_train)
tidy(reg_fit_viviendas)
```

La predicci贸n del precio de la vivienda es -1024072 d贸lares cuando el logaritmo de la variable GrLivArea es 0, y por cada unidad en que el logaritmo base 10 aumenta el precio de la vivienda aumenta 381769 d贸lares

### Representaci贸n de resultados

Hagamos la representaci贸n de los resultados:

```{r}
check_model(reg_fit_viviendas %>% extract_fit_engine())
```

#### Intervalos de confianza de la estimaci贸n

Podemos ver los coeficientes en los que ronda el 95% de probabilidad en que los par谩metros sean los adecuados, mas no la poblaci贸n.


```{r}
confint(reg_fit_viviendas %>% extract_fit_engine())
```

Para esto es importante citar la fuente <https://www.investopedia.com/terms/c/confidenceinterval.asp>

**What Is a Common Misconception About Confidence Intervals?**

The biggest misconception regarding confidence intervals is that they represent the percentage of data from a given sample that falls between the upper and lower bounds. In other words, it would be incorrect to assume that a 99% confidence interval means that 99% of the data in a random sample falls between these bounds. What it actually means is that one can be 99% certain that the range will contain the population mean.

```{r echo = FALSE, results = 'asis'}
image = "https://www.investopedia.com/thmb/mgpezimLowCvuivu5aBE_dChWDI=/750x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/ConfidenceInterval-387c2dddb10c457e9d6041039b5b6e2c.png"
cat(paste0('<center><img src="', image,  '"></center>')) 
```


#### Linealidad

Se espera que entre los residuos no exista tendencia significativa, sin embargo, podemos ver que nuestros residuos siguen una tendencia en forma de U, esto puede ser porque le falta informaci贸n al modelo.

#### ANOVA (Analysis of Variance)

Haciendo un test anova de nuestros predictores vs los residuos, tenemos lo siguientes resultados con respecto a una relaci贸n lineal:

```{r}
ajuste <- reg_fit_viviendas %>% extract_fit_engine()
lm(ajuste$residuals ~ ajuste$fitted.values) %>% anova()
```


Vemos que el p-valor Pr(>F) de la prueba realizada es bastante grande, por lo que no parece existir tendencia lineal entre los residuos.


Ahora lo haremos revisando la tendencia cuadr谩tica.
```{r}
lm(ajuste$residuals ~ I(ajuste$fitted.values^2) + ajuste$fitted.values) %>% anova()
```

Podemos ver que sigue sin existir una tendencia cuadr谩tica


#### Homecedasticidad

```{r}
#Revisar Homecedasticidad
check_heteroscedasticity(ajuste)
```


Podemos ver que no existe `Homecedasticidad` en los residuos, por lo tanto deber铆amos probar a transformar la predictora a ra铆z cuadrada o logaritmo.

#### Diagnosis de Regresi贸n 

Grafiquemos los residuales

```{r}
ggplot(
  tibble("obs" = 1:length(ajuste$residuals),
         "res" = ajuste$residuals),
  aes(x = obs, y = res)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Diagnosis de Regresi贸n", subtitle="Modelo Univariante")+
  theme_economist()
```
Podemos ver que no existe una banda de error definida.


#### Normalidad de los residuos

Podemos ver que en ninguno de los casos supera el test de normalidad, e incluso la recta en el gr谩fico QQ Plot no se sigue, por lo tanto, la recomendaci贸n es transformar la objetivo tomando ra铆z cuadrada, logaritmo o transformaciones Box-Cox para variables positivas, o transformaciones Yeo-Johnson para variables que puedan tomar valores negativos.

```{r}
ols_test_normality(ajuste$residuals)
```

#### Incorrelaci贸n de residuos

```{r}

durbinWatsonTest(ajuste)
```
No hay evidencia suficiente para rechazar la hip贸tesis nula, por lo tanto no podemos asegurar que se encuentran incorrelados.

#### Resumen de evaluaci贸n del modelo

```{r}
glance(reg_fit_viviendas)
```

#### Predicci贸n

Ahora realizaremos la evaluaci贸n y predicci贸n en Test.

```{r}
# Predecimos en tst
fit_viviendas <- reg_wflow_viviendas %>% last_fit(split = viviendas_split)
# Evaluamos en test
fit_viviendas %>% collect_metrics()
```

Vemos que las m茅tricas son muy similares al set de validaci贸n.

```{r}
# Errores en test
pred_test <-
  fit_viviendas %>%
  collect_predictions() %>%
  mutate(error = SalePrice - .pred)
pred_test
```

Calculamos el error y graficamos la predicci贸n con el valor real.


```{r}
# Gr谩ficos en test
ggplot(data = pred_test,
       mapping = aes(x = .pred,
                     y = SalePrice)) +
  geom_point(color = "#006EA1",
             alpha = 0.6,
             size = 4) +
  # Diagonal
  geom_abline(intercept = 0, slope = 1,
              color = "orange", size = 1.2) +
  theme_economist() + 
  labs(title = "Resultados regresi贸n lineal univariante",
       subtitle =
         "Valores deber铆an estar cercanos a la diagonal",
       caption =
         "Autor: Roberto Bonilla| Datos: Ames Housing Dataset",
       x = "Predicciones",
       y = "Valores reales")
```

Podemos ver que los valores est谩n cercanos a la diagonal cuando las casas son de precio medio y bajo, sin embargo, con las casas de precio alto la predicci贸n tiene un error muy alto.


## Fase 4 Regresi贸n Saturada

### Flujo y Evaluaci贸n Regresi贸n Saturada


Primero generamos el modelo lineal, el flujo y evaluamos el modelo con los datos de validaci贸n.

```{r}
# Modelo lineal
reg_lineal <- linear_reg() %>% set_mode("regression") %>% set_engine("lm")

# Flujo de Trabajo
reg_wflow_saturada <-
  workflow() %>% 
  add_model(reg_lineal) %>% 
  add_recipe(rec_reg_saturada)

# Evaluaci贸n del modelo a los datos de validaci贸n
reg_fit_saturada <- 
  reg_wflow_saturada %>%
  fit_resamples(resamples = validation_data)

# M茅tricas de error
reg_fit_saturada |> collect_metrics()


```
Podemos ver muchos mejores resultados con el modelo saturado, teniendo un R cuadrada de .829 y un RMSE de 3197 d贸lares.


### Interpretaci贸n de resultados

```{r}
reg_fit_saturada <-  reg_wflow_saturada %>% fit(viviendas_train)
tidy(reg_fit_saturada)
```

La predicci贸n del precio de la vivienda es 156945.74223 d贸lares cuando el eje 'x' se posiciona en 0 y podemos ver los coeficientes que toman cada una de nuestras variables.

### Representaci贸n de resultados

Hagamos la representaci贸n de los resultados:

```{r}
check_model(reg_fit_saturada %>% extract_fit_engine())
```
Podemos ver que existe colinealidad en nuestras variables y eso puede afectar con ruido en la regresi贸n.

#### Intervalos de confianza de la estimaci贸n

Podemos ver los coeficientes en los que ronda el 95% de probabilidad en que los par谩metros sean los adecuados, mas no la poblaci贸n.


```{r}
confint(reg_fit_saturada %>% extract_fit_engine())
```


#### Linealidad

Se espera que entre los residuos no exista tendencia significativa, y en el gr谩fico podemos observar 

#### ANOVA (Analysis of Variance)

Haciendo un test anova de nuestros predictores vs los residuos, tenemos lo siguientes resultados con respecto a una relaci贸n lineal:

```{r}
ajuste <- reg_fit_saturada %>% extract_fit_engine()
lm(ajuste$residuals ~ ajuste$fitted.values) %>% anova()
```


Vemos que el p-valor Pr(>F) de la prueba realizada es bastante grande, por lo que no parece existir tendencia lineal entre los residuos.


Ahora lo haremos revisando la tendencia cuadr谩tica.
```{r}
lm(ajuste$residuals ~ I(ajuste$fitted.values^2) + ajuste$fitted.values) %>% anova()
```

Podemos ver que sigue sin existir una tendencia cuadr谩tica


#### Homecedasticidad

```{r}
#Revisar Homecedasticidad
check_heteroscedasticity(ajuste)
```


Podemos ver que no existe `Homecedasticidad` en los residuos, por lo tanto deber铆amos probar a transformar la predictora a ra铆z cuadrada o logaritmo.

#### Diagnosis de Regresi贸n 

Grafiquemos los residuales

```{r}
ggplot(
  tibble("obs" = 1:length(ajuste$residuals),
         "res" = ajuste$residuals),
  aes(x = obs, y = res)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Diagnosis de Regresi贸n", subtitle="Modelo Saturado")+
  theme_economist()
```
Podemos ver que no existe una banda de error definida, sin embargo los residuos parecen seguir una recta en su tendencia (lo cual es adecuado).

#### Normalidad de los residuos

Podemos ver que en ninguno de los casos supera el test de normalidad, e incluso la recta en el gr谩fico QQ Plot no se sigue, por lo tanto, la recomendaci贸n es transformar la objetivo tomando ra铆z cuadrada, logaritmo o transformaciones Box-Cox para variables positivas, o transformaciones Yeo-Johnson para variables que puedan tomar valores negativos.

```{r}
ols_test_normality(ajuste$residuals)
```

#### Incorrelaci贸n de residuos

```{r}

durbinWatsonTest(ajuste)
```
No hay evidencia suficiente para rechazar la hip贸tesis nula, por lo tanto no podemos asegurar que se encuentran incorrelados.

#### Resumen de evaluaci贸n del modelo

```{r}
glance(reg_fit_saturada)
```

#### Predicci贸n

Ahora realizaremos la evaluaci贸n y predicci贸n en Test.

```{r}
# Predecimos en tst
fit_saturada <- reg_wflow_saturada %>% last_fit(split = viviendas_split)
# Evaluamos en test
fit_saturada %>% collect_metrics()
```

Vemos que las m茅tricas son muy similares al set de validaci贸n, e incluso tenemos una reducci贸n en el RMSE.

```{r}
# Errores en test
pred_test <-
  fit_saturada %>%
  collect_predictions() %>%
  mutate(error = SalePrice - .pred)
pred_test
```

Calculamos el error y graficamos la predicci贸n con el valor real.


```{r}
# Gr谩ficos en test
ggplot(data = pred_test,
       mapping = aes(x = .pred,
                     y = SalePrice)) +
  geom_point(color = "#006EA1",
             alpha = 0.6,
             size = 4) +
  # Diagonal
  geom_abline(intercept = 0, slope = 1,
              color = "orange", size = 1.2) +
  theme_economist() + 
  labs(title = "Resultados regresi贸n lineal saturada",
       subtitle =
         "Valores deber铆an estar cercanos a la diagonal",
       caption =
         "Autor: Roberto Bonilla| Datos: Ames Housing Dataset",
       x = "Predicciones",
       y = "Valores reales")
```

Podemos ver que los valores est谩n cercanos a la diagonal con mucha m谩s frecuencia, sin embargo, los residuales siguen un poco separados de la recta.


## Fase 4 Regresi贸n con Selecci贸n de Variables por criterio BIC (Bayesian Information Criterion) 

### Selecci贸n Variables


Primero generamos el modelo lineal, el flujo y evaluamos el modelo con los datos de validaci贸n.

```{r }
library(MASS)

# Modelo lineal
bic_prep <- bake(rec_reg_bic %>% prep(), new_data = NULL)
ajuste_bic_multi <- lm(data = bic_prep, SalePrice ~ .)
set.seed(100)
modBIC <- stepAIC(ajuste_bic_multi, k = log(nrow(train_data)))


```

Podemos ver que solamente se ha quedado con 20 variables.


### Receta Regresi贸n con Selecci贸n de Modelos BIC

Ahora procederemos en crear la receta para la regresi贸n penalizada usando el modelo Elastic Net.

```{r}
# Receta
rec_reg_bic <-
  # F贸rmula y datos
  rec_viviendas |> 
  step_rm(has_role("Drop_Columns")) |> 
  step_BoxCox(has_role("boxcox_var")) |>
  step_sqrt(SalePrice) |> 
  step_mutate(across(all_numeric_predictors(), function(x) { ifelse(abs(scores(x,type = "z")) > 2.7 & !is.na(x), NA, x) })) |>
  step_impute_knn(all_numeric_predictors()) |> 
  step_impute_mode(has_role("cuali")) |>
  step_other(has_role("cuali"), threshold = .15, other = "Otros")  |> 
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(all_numeric_predictors(), threshold = 0.8) %>% 
  step_select(SalePrice , LotFrontage , LotArea , YearBuilt , YearRemodAdd , 
    TotalBsmtSF , GrLivArea , GarageArea , LandSlope_Otros , 
    BldgType_Otros , RoofStyle_Hip , HeatingQC_Ex , CentralAir_Otros , 
    KitchenQual_Gd , KitchenQual_Otros , Functional_Otros , Fireplaces_X1 , 
    Fireplaces_Otros , GarageCars_Otros , GarageQual_Otros , 
    Baths_Otros)
rec_reg_bic
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data_bic <- 
  rec_reg_bic |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data_bic)
```


### Flujo y Evaluaci贸n Regresi贸n Univariante


Primero generamos el modelo lineal, el flujo y evaluamos el modelo con los datos de validaci贸n.

```{r}

# Flujo de Trabajo
reg_wflow_bic <-
  workflow() %>% 
  add_model(reg_lineal) %>% 
  add_recipe(rec_reg_bic)

# Evaluaci贸n del modelo a los datos de validaci贸n
reg_fit_bic <- 
  reg_wflow_bic %>%
  fit_resamples(resamples = validation_data)

# M茅tricas de error
reg_fit_bic |> collect_metrics()


```
Podemos ver que el R cuadrada es de .86 y el RMSE es de 31.3454335 d贸lares al cuadrado, es decir, 982.956 d贸lares. Teniendo resultados mucho mejor que el modelo saturado.

### Interpretaci贸n de resultados

```{r}
reg_fit_bic <-  reg_wflow_bic %>% fit(viviendas_train)
tidy(reg_fit_bic)
```

La predicci贸n del precio de la vivienda es el cuadrado de 393.119439 d贸lares cuando el eje 'x' se posiciona en 0 y podemos ver los coeficientes que toman cada una de nuestras variables.

### Representaci贸n de resultados

Hagamos la representaci贸n de los resultados:

```{r}
check_model(reg_fit_bic %>% extract_fit_engine())
```


#### Intervalos de confianza de la estimaci贸n

Podemos ver los coeficientes en los que ronda el 95% de probabilidad en que los par谩metros sean los adecuados, mas no la poblaci贸n.


```{r}
confint(reg_fit_bic %>% extract_fit_engine())
```


#### Linealidad

Se espera que entre los residuos no exista tendencia significativa, y en el gr谩fico podemos observar 

#### ANOVA (Analysis of Variance)

Haciendo un test anova de nuestros predictores vs los residuos, tenemos lo siguientes resultados con respecto a una relaci贸n lineal:

```{r}
ajuste <- reg_fit_bic %>% extract_fit_engine()
lm(ajuste$residuals ~ ajuste$fitted.values) %>% anova()
```


Vemos que el p-valor Pr(>F) de la prueba realizada es bastante grande, por lo que no parece existir tendencia lineal entre los residuos.


Ahora lo haremos revisando la tendencia cuadr谩tica.
```{r}
lm(ajuste$residuals ~ I(ajuste$fitted.values^2) + ajuste$fitted.values) %>% anova()
```

Podemos ver que sigue sin existir una tendencia cuadr谩tica


#### Homecedasticidad

```{r}
#Revisar Homecedasticidad
check_heteroscedasticity(ajuste)
```


Podemos ver que no existe `Homecedasticidad` en los residuos.

#### Diagnosis de Regresi贸n 

Grafiquemos los residuales

```{r}
ggplot(
  tibble("obs" = 1:length(ajuste$residuals),
         "res" = ajuste$residuals),
  aes(x = obs, y = res)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Diagnosis de Regresi贸n", subtitle="Modelo Saturado")+
  theme_economist()
```

Vemos que salvo dos hogares nuestros residuos son homoced谩sticos y existe linealidad entre los residuos.

#### Normalidad de los residuos

Podemos ver que en ninguno de los casos supera el test de normalidad, e incluso la recta en el gr谩fico QQ Plot no se sigue, por lo tanto, la recomendaci贸n es transformar la objetivo tomando ra铆z cuadrada, logaritmo o transformaciones Box-Cox para variables positivas, o transformaciones Yeo-Johnson para variables que puedan tomar valores negativos.

```{r}
ols_test_normality(ajuste$residuals)
```

#### Incorrelaci贸n de residuos

```{r}
durbinWatsonTest(ajuste)
```
No hay evidencia suficiente para rechazar la hip贸tesis nula, por lo tanto no podemos asegurar que se encuentran incorrelados.

#### Resumen de evaluaci贸n del modelo

```{r}
glance(reg_fit_saturada)
```

#### Predicci贸n

Ahora realizaremos la evaluaci贸n y predicci贸n en Test.

```{r}
# Predecimos en tst
fit_bic <- reg_wflow_bic %>% last_fit(split = viviendas_split)
# Evaluamos en test
fit_bic %>% collect_metrics()
```

Vemos que las m茅tricas son muy similares al set de validaci贸n, e incluso tenemos una reducci贸n en el RMSE.

```{r}
# Errores en test
pred_test <-
  fit_bic %>%
  collect_predictions() %>%
  mutate(error = SalePrice - .pred)
pred_test
```

Calculamos el error y graficamos la predicci贸n con el valor real.


```{r}
# Gr谩ficos en test
ggplot(data = pred_test,
       mapping = aes(x = .pred,
                     y = SalePrice)) +
  geom_point(color = "#006EA1",
             alpha = 0.6,
             size = 4) +
  # Diagonal
  geom_abline(intercept = 0, slope = 1,
              color = "orange", size = 1.2) +
  theme_economist() + 
  labs(title = "Resultados regresi贸n lineal con selecci贸n de variables BIC",
       subtitle =
         "Valores deber铆an estar cercanos a la diagonal",
       caption =
         "Autor: Roberto Bonilla| Datos: Ames Housing Dataset",
       x = "Predicciones",
       y = "Valores reales")
```

Podemos ver que los valores est谩n cercanos a la diagonal con mucha m谩s frecuencia, y se ven muy juntos a la recta.


## Fase 4 Regresi贸n Penalizada (Elastic Net)

### Definici贸n del Modelo


Primero generamos el modelo definido por el motor glmnet donde mixture ser谩 el par谩metro 伪 y penalty el par谩metro 位, el flujo y evaluamos el modelo con los datos de validaci贸n.

```{r}
# Modelo lineal
elastic_net <-
  linear_reg(mixture = tune("alpha"), penalty = tune("lambda")) %>%
  set_mode("regression") %>% set_engine("glmnet")
```


### Grid de par谩metros

Y vamos a generar un grid de par谩metros (200 regresiones) usando penalty() (f铆jate que est谩 en escala logar铆tmica, es decir, que -2 es una penalizaci贸n de 0.01 y 2 de 100)

```{r}
grid_elastic_net <-
  expand_grid("alpha" = seq(0, 1, l = 5),
              "lambda" = grid_regular(penalty(range = c(-4, 1)), levels = 40) %>%
                pull(penalty))
```


### Hiperparametrizaci贸n

```{r}
set.seed(100)
wflow_elastic <-
  workflow() %>% add_recipe(rec_reg_elastic) %>% add_model(elastic_net)

mod_elastic <- wflow_elastic %>%
  tune_grid(resamples = cv_folds, grid = grid_elastic_net,
            control = control_grid(verbose = TRUE))

```

### Selecci贸n del mejor modelo

```{r}
# Muestra del mejor modelo en R cuadrada
mod_elastic %>% show_best("rsq")

# Muestra del mejor modelo en RMSE
mod_elastic %>% show_best("rmse")

# Selecci贸n del mejor modelo en R cuadrada
mod_elastic %>% select_best("rsq")

# M茅tricas de error
mod_elastic |> collect_metrics()

```
Podemos ver que el R cuadrada es de .8 y el RMSE es de 39.42, que en valor real de la objetivo es el cuadrado de este n煤mero siendo 1553 d贸lares esto nos da mejores resultados que la regresi贸n multivariante y saturada, pero peores resultados que la regresi贸n con selecci贸n de variables por medio de penalizaci贸n usando BIC.

### Gr谩fica de las m茅tricas en funci贸n de los par谩metros

```{r}
mod_elastic %>% autoplot()
```
Podemos ver que los mejores resultados se pueden percibir cuando el valor lambda es alto y alpha tiene un valor de .25

### Construcci贸n Modelo Final

```{r}
set.seed(100)
elastic_net <-
  linear_reg(mixture = 0.25, penalty =7.443803) %>%
  set_mode("regression") %>% set_engine("glmnet")
wflow_elastic <-
  workflow() %>% add_recipe(rec_reg_elastic) %>% add_model(elastic_net)
mod_elastic_fit <-
  wflow_elastic %>% fit(train_data)
```

### Coeficientes Modelo FInal

Hagamos la representaci贸n del modelo resultante.

```{r}
tidy(mod_elastic_fit)
```

Veamos las variables que ha dejado fuera el modelo:


```{r}
coeficientes <- tidy(mod_elastic_fit)
coeficientes |> filter(estimate==0)
```
Podemos ver las 22 variables que se han quedado fuera de acuerdo al modelo el谩stico.

### Predicci贸n

Ahora realizaremos la evaluaci贸n y predicci贸n en Test.

```{r}
# Predecimos en tst
fit_elastic <- mod_elastic_fit %>% last_fit(split = viviendas_split)
# Evaluamos en test
fit_elastic%>% collect_metrics()
```

Vemos que las m茅tricas son mucho mejores, siendo mejor modelo que los tres anteriores en R cuadrada, y 100 d贸lares por debajo en RMSE que el modelo con selecci贸n usando el criterio BIC.

```{r}
# Errores en test
pred_test <-
  fit_elastic%>%
  collect_predictions() %>%
  mutate(error = SalePrice - .pred)
pred_test
```

Calculamos el error y graficamos la predicci贸n con el valor real.


```{r}
# Gr谩ficos en test
ggplot(data = pred_test,
       mapping = aes(x = .pred,
                     y = SalePrice)) +
  geom_point(color = "#006EA1",
             alpha = 0.6,
             size = 4) +
  theme_economist() + 
  labs(title = "Resultados regresi贸n el谩stica",
       subtitle =
         "Valores deber铆an estar cercanos a la diagonal",
       caption =
         "Autor: Roberto Bonilla| Datos: Ames Housing Dataset",
       x = "Predicciones",
       y = "Valores reales")
```


### Diagnosis de Regresi贸n 

Grafiquemos los residuales

```{r}
ggplot(
  tibble("obs" = 1:length(pred_test$error),
         "res" = pred_test$error),
  aes(x = obs, y = res)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Diagnosis de Regresi贸n", subtitle="Modelo El谩stico")+
  theme_economist()
```
Podemos ver que no existe una banda de error definida, sin embargo los residuos parecen seguir una recta en su tendencia (lo cual es adecuado).
